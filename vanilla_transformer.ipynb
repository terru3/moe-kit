{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b757be9-b268-493c-88a1-53b95db6e9a4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a6e1107-9998-4282-a8ca-0636e3f8e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "686a47d1-9b20-455d-8775-774bff55aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed) # if multi-GPU\n",
    "    torch.backends.cudnn.deterministic=True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abff9a0e-3180-4257-bca3-f76d324b8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d40f5-2bc2-4a3c-ad20-f973978ff1b2",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b05b899-86b9-4414-9f80-e197b9d3d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: vt_4_LAYERs_4_HEAD_128_EMBD_DIM_128_SEQ_LEN\n"
     ]
    }
   ],
   "source": [
    "path = './'\n",
    "\n",
    "EPOCHS = 100\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LEN = 128\n",
    "PRINT_ITER = 50 # frequency to print train loss\n",
    "EVAL_ITERS = 100 # number of batches to estimate val loss with\n",
    "N_EMBD = 128\n",
    "N_FF = N_EMBD * 4\n",
    "N_HEAD = 4\n",
    "N_LAYER = 4\n",
    "\n",
    "MODEL_NAME = f\"vt_{N_LAYER}_LAYERs_{N_HEAD}_HEAD_{N_EMBD}_EMBD_DIM_{SEQ_LEN}_SEQ_LEN\"\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d713212-4a60-4e60-90f4-f6e0a704a299",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09b6d9fe-8f18-474d-aefb-4e44fd0b27d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Vocab size: 65\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{path}/data/tiny-shakespeare.txt\", 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print(f'Vocab: {chars}')\n",
    "print(f'Vocab size: {VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "545415c0-5e49-42c9-b10a-1432028233b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 47, 52, 63, 7, 57, 46, 39, 49, 43, 57, 54, 43, 39, 56, 43, 1, 47, 57, 1, 57, 47, 41, 49]\n",
      "tiny-shakespeare is sick\n"
     ]
    }
   ],
   "source": [
    "# Prepare mappings / tokenizer\n",
    "# create a mapping from characters to integers\n",
    "txt2idx = { ch:i for i,ch in enumerate(chars) }\n",
    "idx2txt = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [txt2idx[c] for c in s]\n",
    "decode = lambda l: ''.join([idx2txt[i] for i in l])\n",
    "\n",
    "print(encode(\"tiny-shakespeare is sick\"))\n",
    "print(decode(encode(\"tiny-shakespeare is sick\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f0124c4-58be-4acd-8249-fd9e5cecbaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data len: 1003854 val_data len: 111540\n"
     ]
    }
   ],
   "source": [
    "# tokenizer data\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # 90-10 split\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print('train_data len:', len(train_data), 'val_data len:', len(val_data))\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - SEQ_LEN, (BATCH_SIZE,))\n",
    "    x = torch.stack([data[i:i+SEQ_LEN] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+SEQ_LEN+1] for i in ix])\n",
    "    return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a187b-253f-4af1-b6d1-763f4dcc03e2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f49faf9d-31ff-4fc1-96eb-7b30e7be74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_embd, n_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(n_ff, n_embd),\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec5127cd-7838-48f9-9c09-62e131d57ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_embd = n_embd\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = n_embd // n_head # Dimension of each head's key, query, and value\n",
    "        \n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.query = nn.Linear(n_embd, n_embd, bias=False)\n",
    "        self.key = nn.Linear(n_embd, n_embd, bias=False)\n",
    "        self.value = nn.Linear(n_embd, n_embd, bias=False)\n",
    "        self.out = nn.Linear(n_embd, n_embd, bias=False)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        B, S, D = x.size()\n",
    "        # split dimension into n_head * head_dim, then transpose the sequence length w/ n_head\n",
    "        # output: [B, n_head, S, head_dim]\n",
    "        return x.view(B, S, self.n_head, self.head_dim).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        B, _, S, head_dim = x.size() # _ is n_head which we will merge\n",
    "        # output: [B, S, n_embd]\n",
    "        return x.transpose(1, 2).contiguous().view(B, S, self.n_embd)\n",
    "\n",
    "    def scaled_dot_product(self, q, k, v, dropout, mask=None):\n",
    "        # q,k,v are [B, n_head, S, head_dim]\n",
    "        # wei = [B, n_head, S, S]\n",
    "        wei = q @ k.transpose(-2,-1) / np.sqrt(self.head_dim)\n",
    "        # mask is [B, 1, S, S]\n",
    "        if mask is not None:\n",
    "          wei = wei.masked_fill(mask, float('-inf'))\n",
    "        wei = dropout(F.softmax(wei, dim=-1))\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # x: (B, S, n_embd)\n",
    "        # Step 1 and 2: Project full query, key, value, then split via reshaping\n",
    "        q = self.split_heads(self.query(x))\n",
    "        k = self.split_heads(self.key(x))\n",
    "        v = self.split_heads(self.value(x))\n",
    "\n",
    "        # Step 3: Compute scaled dot-product attention with causal mask\n",
    "        attn = self.scaled_dot_product(q, k, v, self.drop, mask)\n",
    "\n",
    "        # Step 4 and 5: Concatenate attention scores, return projected output matrix\n",
    "        out = self.out(self.combine_heads(attn)) # (B, S, n_embd)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e21ecbfe-33be-4062-ad26-eb3ebf68eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, n_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.sa = MultiHeadAttention(n_embd, n_head, dropout)\n",
    "        self.mlp = MLP(n_embd, n_ff, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # residual connection (stream)\n",
    "        # pre layer norm\n",
    "        x = x + self.drop(self.sa(self.ln1(x), mask))\n",
    "        x = x + self.drop(self.mlp(self.ln2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f205ee3-0034-48d1-9715-d6628c59f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "  \"\"\"\n",
    "  Formula taken from the original Transformer paper:\n",
    "  PE(pos, 2i (even)) = sin(pos/(10000^{2i/d_model}))\n",
    "  PE(pos, 2i+1 (odd)) = cos(pos/(10000^{2i/d_model}))\n",
    "\n",
    "  See reference for more details:\n",
    "  https://kikaben.com/transformers-positional-encoding/\n",
    "  \"\"\"\n",
    "  def __init__(self, d_model, max_len):\n",
    "      # just set d_model = n_embd and max_len = seq_len\n",
    "      super().__init__()\n",
    "\n",
    "      position = torch.arange(max_len).unsqueeze(1) # [max_len, 1]\n",
    "      divisor = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model)) # [d_model / 2, half for each of sin and cos]\n",
    "      pe = torch.zeros(max_len, d_model)\n",
    "      pe[:, 0::2] = torch.sin(position * divisor)\n",
    "      pe[:, 1::2] = torch.cos(position * divisor)\n",
    "      self.register_buffer('pe', pe) # result: self.pe = [max_len, d_model], mapping each token index to a vector of length d_model as desired\n",
    "\n",
    "  def forward(self, x):\n",
    "      # x = torch.arange(seq_length) has shape [seq_length], so x.size(0) extracts it, then we index self.pe for the first seq_length mappings\n",
    "      # note we do not add the positional embeddings to x itself yet, we simply return them\n",
    "      # output = (seq_length, d_model=n_embd)\n",
    "      return self.pe[:x.size(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "421b67b4-315b-4370-97bc-200c057484bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_length,\n",
    "                 n_embd, n_head, n_ff, n_layer,\n",
    "                 device, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = PositionalEncoding(n_embd, seq_length)\n",
    "\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd,\n",
    "                                            n_head,\n",
    "                                            n_ff,\n",
    "                                            dropout) for _ in range(n_layer)])\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.seq_length = seq_length\n",
    "        self.device = device\n",
    "        self.init_params()\n",
    "\n",
    "    # weight initialization (Xavier uniform)\n",
    "    def init_params(self, default_initialization=False):\n",
    "        if not default_initialization:\n",
    "            for name, p in self.named_parameters():\n",
    "                if p.dim() > 1:\n",
    "                    nn.init.xavier_uniform_(p)\n",
    "\n",
    "    # Remark: Xavier normal is not supported at this time.\n",
    "\n",
    "    def get_causal_mask(self,  x):\n",
    "        \"\"\"\n",
    "        Generates causal mask for decoding\n",
    "        \"\"\"\n",
    "        B, S = x.shape # x = (batch_size x seq_len)\n",
    "        attn_shape = (B, 1, S, S)\n",
    "        subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8') # k = 1 shifts the diagonal, so that the main diagonal gets 0's\n",
    "        return (torch.from_numpy(subsequent_mask) == 0).to(self.device)\n",
    "        # True along main diagonal + below, False elsewhere\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.to(torch.int64)\n",
    "        B, S = x.shape\n",
    "\n",
    "        # get mask\n",
    "        mask = self.get_causal_mask(x).to(self.device)\n",
    "        # mask = (B x 1 x S x S)\n",
    "\n",
    "        tok_emb = self.token_embedding(x)\n",
    "        pos_emb = self.position_embedding(torch.arange(S))\n",
    "        x = self.drop(tok_emb + pos_emb)\n",
    "        # (B, S, n_embd)\n",
    "        for block in self.blocks:\n",
    "            x = block(x, ~mask) # (B, S, n_embd)\n",
    "        # negate mask to fill originally False values with -inf later\n",
    "        logits = self.lm_head(x) # (B, S, vocab_size)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def generate(self, input_ids, method='multinomial',\n",
    "                 max_new_tokens=1000, temp=None,\n",
    "                 num_beams=None, p_nucleus=None, k=None):\n",
    "\n",
    "        # input_ids begins as (B, S)\n",
    "        self.eval()\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            if method in ['multinomial', 'temperature', 'greedy', 'nucleus', 'top-k']:\n",
    "                # i) Truncate to the most recent `max length` tokens\n",
    "                text_cond = input_ids[:, -self.seq_length:]\n",
    "                # ii) Retrieve predictions\n",
    "                with torch.no_grad():\n",
    "                    logits = self(text_cond)\n",
    "                # model output: (B, S, vocab_size)\n",
    "                # iii) Find last token logits of each\n",
    "                logits = logits[:, -1, :] # (B, vocab_size)\n",
    "\n",
    "                # if temperature sampling, divide logits by temp before applying softmax\n",
    "                if method == 'temperature':\n",
    "                    logits = logits / temp\n",
    "\n",
    "                # iv) Take softmax along each\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "                # v) Sample next token depending on method\n",
    "                if method == 'greedy':\n",
    "                    next_idx = probs.argmax(dim=-1).unsqueeze(-1)\n",
    "\n",
    "                elif method in ['multinomial', 'temperature', 'nucleus', 'top-k']:\n",
    "                    if method == 'nucleus':\n",
    "                        assert p_nucleus is not None and (0 < p_nucleus) and (p_nucleus <= 1)\n",
    "\n",
    "                        sorted_probs, sorted_idx = probs.sort(dim=-1, descending=True)\n",
    "                        prob_cumsum = sorted_probs.cumsum(dim=-1)\n",
    "                        idx_remove = prob_cumsum > p_nucleus\n",
    "                        # shift one right to ensure the first token is above the threshold\n",
    "                        idx_remove[..., 1:] = idx_remove[..., :-1].clone()\n",
    "                        idx_remove[..., 0] = False\n",
    "                        # retrieve original indices by reverse-sorting\n",
    "                        remove_mask = idx_remove.gather(dim=-1,\n",
    "                                          index=sorted_idx.argsort(dim=-1))\n",
    "                        # ^ specifically, we do this by first argsorting the indices which were returned from argsort\n",
    "                        # you can show that this returns indices that when used to subset a sorted array, returns the original array in unsorted order\n",
    "                        # https://stackoverflow.com/questions/52127723/pytorch-better-way-to-get-back-original-tensor-order-after-torch-sort\n",
    "                        probs[remove_mask] = 0\n",
    "\n",
    "                    if method == 'top-k':\n",
    "                        remove_mask = probs < torch.topk(probs, k).values[..., -1, None] # topk returns (B, 1), leaving only the\n",
    "                        # kth largest probs (i.e. the cutoff value for each). Then mask is same size as probs (B, vocab_size)\n",
    "                        probs[remove_mask] = 0\n",
    "\n",
    "                    # Sample probabilistically via scores\n",
    "                    next_idx = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "\n",
    "                # vi) Autoregressively append to input_text\n",
    "                input_ids = torch.cat((input_ids, next_idx), dim=-1)\n",
    "\n",
    "                # now input_text = (B, S + 1)\n",
    "\n",
    "        return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af611b-be70-4737-84df-f7bf13b057c9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "679ef31f-5253-49f9-9e24-c64b05655cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(23)\n",
    "model = VanillaTransformer(VOCAB_SIZE, SEQ_LEN,\n",
    "                 N_EMBD, N_HEAD, N_FF, N_LAYER,\n",
    "                 device, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7eacebc5-8b3a-4c5d-9c89-f946fd25e948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "VanillaTransformer                       --\n",
       "├─Embedding: 1-1                         8,320\n",
       "├─PositionalEncoding: 1-2                --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Block: 2-1                        --\n",
       "│    │    └─MultiHeadAttention: 3-1      65,536\n",
       "│    │    └─MLP: 3-2                     131,712\n",
       "│    │    └─LayerNorm: 3-3               256\n",
       "│    │    └─LayerNorm: 3-4               256\n",
       "│    │    └─Dropout: 3-5                 --\n",
       "│    └─Block: 2-2                        --\n",
       "│    │    └─MultiHeadAttention: 3-6      65,536\n",
       "│    │    └─MLP: 3-7                     131,712\n",
       "│    │    └─LayerNorm: 3-8               256\n",
       "│    │    └─LayerNorm: 3-9               256\n",
       "│    │    └─Dropout: 3-10                --\n",
       "│    └─Block: 2-3                        --\n",
       "│    │    └─MultiHeadAttention: 3-11     65,536\n",
       "│    │    └─MLP: 3-12                    131,712\n",
       "│    │    └─LayerNorm: 3-13              256\n",
       "│    │    └─LayerNorm: 3-14              256\n",
       "│    │    └─Dropout: 3-15                --\n",
       "│    └─Block: 2-4                        --\n",
       "│    │    └─MultiHeadAttention: 3-16     65,536\n",
       "│    │    └─MLP: 3-17                    131,712\n",
       "│    │    └─LayerNorm: 3-18              256\n",
       "│    │    └─LayerNorm: 3-19              256\n",
       "│    │    └─Dropout: 3-20                --\n",
       "├─Linear: 1-4                            8,385\n",
       "├─Dropout: 1-5                           --\n",
       "=================================================================\n",
       "Total params: 807,745\n",
       "Trainable params: 807,745\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a48e940d-c7af-4367-81a9-3310531dc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(logits, targets):\n",
    "    B, S, C = logits.shape\n",
    "    logits = logits.view(B*S, C)\n",
    "    targets = targets.view(B*S)\n",
    "    loss = F.cross_entropy(logits, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "af0a898b-5f96-44da-ac41-9a23616ebfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/10000 | Loss: 6.962159633636475\n",
      "Step 50/10000 | Loss: 3.401878595352173\n",
      "Step 100/10000 | Loss: 3.175950765609741\n",
      "Step 150/10000 | Loss: 2.812167167663574\n",
      "Step 200/10000 | Loss: 2.6810946464538574\n",
      "Step 250/10000 | Loss: 2.664418935775757\n",
      "Step 300/10000 | Loss: 2.659294366836548\n",
      "Step 350/10000 | Loss: 2.694620370864868\n",
      "Step 400/10000 | Loss: 2.6138129234313965\n",
      "Step 450/10000 | Loss: 2.5488266944885254\n",
      "Step 500/10000 | Loss: 2.5062320232391357\n",
      "Step 550/10000 | Loss: 2.4803411960601807\n",
      "Step 600/10000 | Loss: 2.4527230262756348\n",
      "Step 650/10000 | Loss: 2.38985013961792\n",
      "Step 700/10000 | Loss: 2.3893115520477295\n",
      "Step 750/10000 | Loss: 2.3820767402648926\n",
      "Step 800/10000 | Loss: 2.32847261428833\n",
      "Step 850/10000 | Loss: 2.3164374828338623\n",
      "Step 900/10000 | Loss: 2.2766780853271484\n",
      "Step 950/10000 | Loss: 2.297649383544922\n",
      "Step 1000/10000 | Loss: 2.2336761951446533\n",
      "Step 1050/10000 | Loss: 2.255802869796753\n",
      "Step 1100/10000 | Loss: 2.123323440551758\n",
      "Step 1150/10000 | Loss: 2.198436737060547\n",
      "Step 1200/10000 | Loss: 2.165727376937866\n",
      "Step 1250/10000 | Loss: 2.104663133621216\n",
      "Step 1300/10000 | Loss: 2.106135129928589\n",
      "Step 1350/10000 | Loss: 2.0613210201263428\n",
      "Step 1400/10000 | Loss: 2.0755412578582764\n",
      "Step 1450/10000 | Loss: 2.054353952407837\n",
      "Step 1500/10000 | Loss: 1.9930700063705444\n",
      "Step 1550/10000 | Loss: 2.0012974739074707\n",
      "Step 1600/10000 | Loss: 2.0864081382751465\n",
      "Step 1650/10000 | Loss: 2.019371747970581\n",
      "Step 1700/10000 | Loss: 1.9948196411132812\n",
      "Step 1750/10000 | Loss: 1.9606355428695679\n",
      "Step 1800/10000 | Loss: 1.9251341819763184\n",
      "Step 1850/10000 | Loss: 1.913225769996643\n",
      "Step 1900/10000 | Loss: 1.843820333480835\n",
      "Step 1950/10000 | Loss: 1.9268293380737305\n",
      "Step 2000/10000 | Loss: 1.9561188220977783\n",
      "Step 2050/10000 | Loss: 1.885495662689209\n",
      "Step 2100/10000 | Loss: 1.815986156463623\n",
      "Step 2150/10000 | Loss: 1.8532180786132812\n",
      "Step 2200/10000 | Loss: 1.8662980794906616\n",
      "Step 2250/10000 | Loss: 1.827746868133545\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m calc_loss(logits, targets)\n\u001b[1;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[103], line 54\u001b[0m, in \u001b[0;36mVanillaTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# (B, S, n_embd)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 54\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, S, n_embd)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# negate mask to fill originally False values with -inf later\u001b[39;00m\n\u001b[1;32m     56\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x) \u001b[38;5;66;03m# (B, S, vocab_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[101], line 14\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# residual connection (stream)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# pre layer norm\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(x), mask))\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[99], line 13\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/moe-kit/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "for step in range(10000): # around 50 min per 10000 steps, so 3.3 batches/sec = 53 samples per sec = 6780 char/s\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    inputs, targets = get_batch('train')\n",
    "    logits = model(inputs)\n",
    "    loss = calc_loss(logits, targets)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % PRINT_ITER == 0:\n",
    "        print(f\"Step {step}/10000 | Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff60e40-9e28-4b4f-b8b9-75a758875531",
   "metadata": {},
   "source": [
    "### TODO: Build out train, eval functions. embed functionality to save val losses and benchmark tokens (characters) per sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca27c6e-2d5f-4131-87fa-275d8bc35f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, optimizer, device, \n",
    "#           train_loss_list=None, val_loss_list=None):\n",
    "\n",
    "#     train_losses = train_loss_list if train_loss_list is not None else []\n",
    "#     val_losses = val_loss_list if val_loss_list is not None else []\n",
    "\n",
    "#     model.train()\n",
    "#     model.to(device)\n",
    "\n",
    "#     # Set up prompt generation\n",
    "#     # CREATE the relevant folders before uncommenting!\n",
    "#     # generation_file_path = f\"{path}/vanilla_transformer/outputs/OUTPUT_{MODEL_NAME}.txt\"\n",
    "#     empty_tokens = torch.zeros((1, 1), dtype=torch.long).to(device)\n",
    "#     cond_prompts = [\"Thou art\"]\n",
    "\n",
    "#     cond_token_list = [encode(prompt) for prompt in cond_prompts]\n",
    "\n",
    "#     #loop over epochs\n",
    "\n",
    "#         val_losses = estimate_loss(model)\n",
    "\n",
    "#     #generate from model every time we estimate val loss\n",
    "#              generate()\n",
    "#         for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "#             start = time.perf_counter()\n",
    "\n",
    "#             optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "#             inputs, targets = get_batch('train')\n",
    "\n",
    "#             logits = model(inputs)\n",
    "\n",
    "#             loss = calc_loss(logits, targets)\n",
    "\n",
    "#             loss.backward()\n",
    "\n",
    "#             # Monitor gradient norm\n",
    "#             grads = [\n",
    "#                     param.grad.detach().flatten()\n",
    "#                     for param in model.parameters()\n",
    "#                     if param.grad is not None\n",
    "#                 ]\n",
    "#             norm = torch.cat(grads).norm()\n",
    "\n",
    "#             optimizer.step()\n",
    "\n",
    "#             train_times.append(time.perf_counter()-start)\n",
    "\n",
    "#             if step % 25 == 0:\n",
    "#                 if step != 0: # avoid clashing with validation print statement\n",
    "#                     print(f\"Epoch: {epoch+1}/{EPOCHS} | Step: {step}/{len(train_dataloader)} | Train Loss: {loss.item():.5f} |\",\n",
    "#                               f\"Grad Norm: {norm:.5f} | Avg Tokens/Sec: \")\n",
    "\n",
    "#                 train_losses.append(loss.item())\n",
    "\n",
    "#         # create hyperparam for save frequency\n",
    "#         with open(f'{path}/vanilla_transformer/train_logs/{MODEL_NAME}_train_losses.json', 'w') as f:\n",
    "#           json.dump(train_losses, f)\n",
    "\n",
    "#         with open(f'{path}/vanilla_transformer/train_logs/{MODEL_NAME}_val_losses.json', 'w') as f2:\n",
    "#           json.dump(val_losses, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abba78-5cd4-4ee7-b116-203fdeef3b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def estimate_loss(val_losses):\n",
    "#     model.eval()\n",
    "#     losses = torch.zeros(EVAL_ITERS)\n",
    "#     for k in range(EVAL_ITERS):\n",
    "#         inputs, targets = get_batch('test')\n",
    "#         logits = model(inputs, targets)\n",
    "#         losses[k] = calc_loss(logits, targets).item()\n",
    "#     val_loss = losses.mean()\n",
    "#     val_losses.append(val_loss)\n",
    "#     model.train()\n",
    "#     print(f\"Est. Val Loss: {val_loss:.5f}\")\n",
    "#     return val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44ceb7-9dfe-4591-b7e4-b2486bb0eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate(model, generation_file_path, empty_tokens, cond_token_list):\n",
    "#     #TODO\n",
    "#     generation_text = f\"\"\"{MODEL_NAME} Output\n",
    "#     UNCONDITIONAL GENERATION:\n",
    "\n",
    "#     Top-k (5) (250 max_tokens):\n",
    "#     {uncond_res1}\n",
    "\n",
    "#     Nucleus (0.5) (250 max_tokens):\n",
    "#     {uncond_res3}\n",
    "\n",
    "#     #####################################################\n",
    "#     CONDITIONAL GENERATION (Top-k (5), 250 max_tokens):\n",
    "#     {cond_res_list}\n",
    "#     -----------------------------------------------------\n",
    "#     \"\"\"\n",
    "#     with open(generation_file_path, 'a') as file:\n",
    "#       file.write(generation_text)\n",
    "#     print(generation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5840a0c-62b9-4011-a370-8cdf1ba4be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(model, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf95154-d641-4d9b-9e8a-c054d5921921",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66ee940-9794-467a-8088-2b59ac5aaeae",
   "metadata": {},
   "source": [
    "*After 2250 steps *  16 batch_size, training loss 1.8277:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "67bda2ae-5fa0-4120-9b55-41121d9ca152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AUCENTIO:\n",
      "Which the may sich that nough to the slay'd one so to;\n",
      "His be knot, I Vistrengs, thy the good our kim in to call:\n",
      "No, thou man I good, Say, for pmburds tell eack.\n",
      "\n",
      "HESSend.\n",
      "\n",
      "MENCIO:\n",
      "Dever and will'd my Vaing, life to suke in lise,\n",
      "These'll was of yret, fol smy his no Fear shom gestard:\n",
      "Retil appoutis commentex e'epon tend her his him buse,\n",
      "And what ityer am the iends, come; God foll ding:\n",
      "by appeerk.\n",
      "\n",
      "LOUCIO:\n",
      "Petwild, bake you, that I same, what wear;\n",
      "from in in or my speak as For Jul\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "772a7473-2e8f-4c61-87d9-612e01150b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERRY: thou arte a my she\n",
      "Which have may and of contain.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Good as I tall no knrow, for shalt agarnt\n",
      "And mpo; and Kong a m, not outhpile Mesce.\n",
      "\n",
      "HENRY VI:\n",
      "When I will thy lookess, oner the pexstrey\n",
      "The the the hee voagh gresed livioe.\n",
      "\n",
      "MENCIO:\n",
      "My her callis his peaced of to that\n",
      "We where's by shall bore: as shall myselvea\n",
      "The plender feuls!\n",
      "\n",
      "PAPELLANT:\n",
      "In the the into balby me dods to love,\n",
      "In but the giving of nyou ase. I tall it-me?'e Goveuling\n",
      "The theer haught art praver count madeng Camen:\n",
      "T\n"
     ]
    }
   ],
   "source": [
    "input_txt = \"TERRY: thou art\"\n",
    "ctx = encode(input_txt)\n",
    "print(decode(model.generate(torch.tensor(ctx).unsqueeze(0).long(), max_new_tokens=500)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
